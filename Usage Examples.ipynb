{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MakiFlow usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains basic guidelines of using MakiFlow. MakiFlow is not a serious framework like PyTorch or TensorFlow, this is an instrument I built in order to improve quality and speed of my researches in the field of Neural Networks, especially CNNs. If you found this library useful and have some thoughs how to improve it or what to fix I'd like to listen to you. My email: igor.kilbas@mail.ru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing MakiFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I don't know how to create high quality libraries, you're gonna have some pain. Here is the way I import MakiFlow on my computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/student401/MakiFlow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CNN based on MakiFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have an access to MakiFlow and can import stuff related to it.\n",
    "In order to create CNN you need to defined layers order first. Here is what I mean by that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.layers import ConvLayer, DenseLayer, MaxPoolLayer, FlattenLayer\n",
    "\n",
    "layers = [\n",
    "        ConvLayer(kw=3, kh=3, in_f=3, out_f=64, name='input_layer'),\n",
    "        ConvLayer(kw=3, kh=3, in_f=64, out_f=64, name=2),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        ConvLayer(kw=3, kh=3, in_f=64, out_f=128, name=4),\n",
    "        ConvLayer(kw=3, kh=3, in_f=128, out_f=128, name=5),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        ConvLayer(kw=3, kh=3, in_f=128, out_f=256, name=6),\n",
    "        ConvLayer(kw=3, kh=3, in_f=256, out_f=256, name=7),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        ConvLayer(kw=3, kh=3, in_f=256, out_f=512, name=8),\n",
    "        ConvLayer(kw=3, kh=3, in_f=512, out_f=512, name=9),\n",
    "        ConvLayer(kw=3, kh=3, in_f=512, out_f=512, name=10),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        FlattenLayer(),\n",
    "        DenseLayer(input_shape=2048, output_shape=1024, name=12),\n",
    "        DenseLayer(input_shape=1024, output_shape=1024, name=13),\n",
    "        DenseLayer(input_shape=1024, output_shape=10, activation=None, name='out_put_layer')\n",
    "    # The last layer always is gonna have no activation function! Just always pass None into 'activation' argument!\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built basic VGG model. As you might have noticed, you have to directly pass the number of input feature maps and output feature maps, so be careful with that. Tip: number of the input feature maps in the next layer equals number of the feature maps in the previous layer. Anyway, TensorFlow will get you know if something is wrong.\n",
    "\n",
    "To create CNN, we need ConvModel class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow import ConvModel\n",
    "\n",
    "model = ConvModel(layers=layers, input_shape=[64, 32, 32, 3], output_shape=[64, 10], name='My_MakiFlow_little_VGG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You've just created your first CNN based on MakiFlow! But we still have some stuff to do.\n",
    "\n",
    "First, ConvModel requires TensorFlow Session in order to work. You can treat ConvModel as a car and Session as an engine. Let's add an engine to our car:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "session = tf.Session()\n",
    "model.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model. Let's train it. We'll use cifar10 dataset for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = cifar10.load_data()\n",
    "    \n",
    "Xtrain = Xtrain.astype(np.float32)\n",
    "Xtest = Xtest.astype(np.float32)\n",
    "\n",
    "Xtrain /= 255\n",
    "Xtest /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Ytrain = keras.utils.to_categorical(Ytrain, 10)\n",
    "Ytest = keras.utils.to_categorical(Ytest, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second step is to define our training parameters:\n",
    "learning_rate;\n",
    "optimizer - ConvModel uses TensorFlow optimizers in order to train the model;\n",
    "epochs;\n",
    "\n",
    "We will use RMSProp for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "lr = 1e-5*128\n",
    "epsilon = 1e-6\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=lr, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model we can call two methods:\n",
    "verbose_fit - tests the model on train data and test data;\n",
    "pure_fit - tests the model only on test data, it works much faster than verbose_fit.\n",
    "\n",
    "We will use pure fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [00:13<00:00, 57.80it/s]\n",
      "  0%|          | 0/781 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train accuracy: 0.2597880006723787 Train cost: 1.9747080735386964 Test accuracy 0.22870000000000001 Test cost 2.4128412099984975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [00:12<00:00, 61.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train accuracy: 0.4819966682592617 Train cost: 1.418893301204675 Test accuracy 0.5457000000000001 Test cost 1.2490314581455328\n"
     ]
    }
   ],
   "source": [
    "info = model.pure_fit(Xtrain, Ytrain, Xtest, Ytest, optimizer=optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pure_fit method returns dictionary with tests' info on each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train costs': [1.9747080735386964, 1.418893301204675],\n",
       " 'train errors': [0.7402119993276213, 0.5180033317407383],\n",
       " 'test costs': [2.4128412099984975, 1.2490314581455328],\n",
       " 'test errors': [0.7713, 0.4543]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions using MakiFlow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make predictions, we use predict method. \n",
    "This method requires tensor of shape (number_of_samples, dim, dim, channels).\n",
    "It always returns numpy array with probabilities of belonging this particular sample(or samples) to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01108474, 0.00861162, 0.12099435, 0.36020404, 0.06199497,\n",
       "        0.27742323, 0.10490333, 0.03577648, 0.01214113, 0.00686607]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xtest[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
